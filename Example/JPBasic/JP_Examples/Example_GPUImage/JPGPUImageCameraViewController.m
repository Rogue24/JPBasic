//
//  JPGPUImageCameraViewController.m
//  JPBasic_Example
//
//  Created by å‘¨å¥å¹³ on 2020/2/13.
//  Copyright Â© 2020 zhoujianping24@hotmail.com. All rights reserved.
//

#import "JPGPUImageCameraViewController.h"
#import "AVPlayerViewController+JPExtension.h"
#import "GPUImageBeautifyFilter.h"
#import "JPImageFilter.h"
#import "UIAlertController+JPExtension.h"
#import "LFGPUImageBeautyFilter.h"
#import "JPMovieWriter.h"
#import "JPWatermarkElement.h"
#import "JPPhotoTool.h"

#if __has_include(<GPUImage/GPUImage.h>)
#import <GPUImage/GPUImage.h>
#elif __has_include("GPUImage/GPUImage.h")
#import "GPUImage/GPUImage.h"
#else
#import "GPUImage.h"
#endif

@interface JPGPUImageCameraViewController () <JPMovieWriterDelegate> //<GPUImageMovieWriterDelegate>
@property (weak, nonatomic) IBOutlet UIImageView *placeholderView;
@property (weak, nonatomic) IBOutlet GPUImageView *previewView;
@property (weak, nonatomic) IBOutlet UIImageView *writeLastView;
@property (weak, nonatomic) IBOutlet UIView *userGrView;
@property (weak, nonatomic) IBOutlet UISlider *slider;

@property (nonatomic, strong) GPUImageStillCamera *camera;

@property (nonatomic, weak) GPUImageBrightnessFilter *brightnessFilter;
@property (nonatomic, weak) GPUImageSketchFilter *sketchFilter;
@property (nonatomic, weak) GPUImagePixellateFilter *pixellateFilter;

@property (nonatomic, strong) LFGPUImageBeautyFilter *beautifyFilter;
@property (nonatomic, weak) JPImageFilter *imageFilter;

@property (nonatomic, weak) GPUImageFilterGroup *filterGroup;

@property (nonatomic, strong) GPUImagePicture *lookupImageSource;
@property (nonatomic, strong) GPUImageLookupFilter *lookupFilter;

@property (nonatomic, strong) GPUImageSwirlFilter *swirlFilter;
@property (nonatomic, strong) CADisplayLink *link;
@property (nonatomic, assign) BOOL isPaning;

//@property (nonatomic, weak) GPUImageMovieWriter *movieWriter;
@property (nonatomic, weak) JPMovieWriter *movieWriter;

@property (nonatomic, strong) GPUImageAlphaBlendFilter *blendFilter;
//@property (nonatomic, strong) GPUImageUIElement *element;
@property (nonatomic, strong) JPWatermarkElement *element; // ä¿®æ­£åçš„GPUImageUIElement
@property (nonatomic, strong) UIImageView *watermark;
@end

@implementation JPGPUImageCameraViewController
{
    BOOL _isPreviewing;
}

// è®¾ç½®å¤„ç†é“¾æ¡ï¼ˆä¸€å±‚ä¸€å±‚å¾€ä¸Šå ï¼‰
// camera -> bilateralFilterï¼ˆç£¨çš®ï¼‰ -> brightnessFilterï¼ˆç¾ç™½ï¼‰ -> previewView
// [self.camera addTarget:bilateralFilter];
// [bilateralFilter addTarget:brightnessFilter];
// [brightnessFilter addTarget:self.previewView];

#pragma mark - ç¼–ç å‚æ•°

- (NSDictionary *)videoOutputSettings:(CGSize)videoSize {
#pragma mark å‚è€ƒäºï¼šhttps://blog.csdn.net/sinat_31177681/article/details/75252341
//    // å†™å…¥è§†é¢‘å¤§å°
//    NSInteger numPixels = videoSize.width * videoSize.height;
//    // æ¯åƒç´ æ¯”ç‰¹
//    CGFloat bitsPerPixel = 6.0;
//    NSInteger bitsPerSecond = numPixels * bitsPerPixel;
//    // ç ç‡å’Œå¸§ç‡è®¾ç½®
//    NSDictionary *compressionProperties =
//        @{AVVideoAverageBitRateKey: @(bitsPerSecond),
//          AVVideoExpectedSourceFrameRateKey: @(15),
//          AVVideoMaxKeyFrameIntervalKey: @(15),
//          AVVideoProfileLevelKey: AVVideoProfileLevelH264BaselineAutoLevel};
//    return @{AVVideoCodecKey: AVVideoCodecH264,
//             AVVideoScalingModeKey: AVVideoScalingModeResizeAspectFill,
//             AVVideoWidthKey: @(videoSize.width),
//             AVVideoHeightKey: @(videoSize.height),
//             AVVideoCompressionPropertiesKey: compressionProperties};
    
#pragma mark æºç çš„è®¾ç½®ï¼Œæœ‰å¾…è€ƒé‡
    NSDictionary *videoCleanApertureSettings = @{AVVideoCleanApertureWidthKey: @(videoSize.width),
                                                 AVVideoCleanApertureHeightKey: @(videoSize.height),
                                                 AVVideoCleanApertureHorizontalOffsetKey: @0,
                                                 AVVideoCleanApertureVerticalOffsetKey: @0};
    NSDictionary *videoAspectRatioSettings = @{AVVideoPixelAspectRatioHorizontalSpacingKey: @3,
                                               AVVideoPixelAspectRatioVerticalSpacingKey: @3};
    NSDictionary *compressionProperties = @{AVVideoCleanApertureKey: videoCleanApertureSettings,
                                            AVVideoPixelAspectRatioKey: videoAspectRatioSettings,
                                            AVVideoAverageBitRateKey: @(1000000), // 2000000 é™ä½ç ç‡ ä½“ç§¯æ›´å°
                                            AVVideoMaxKeyFrameIntervalKey: @16,
                                            AVVideoProfileLevelKey: AVVideoProfileLevelH264Main31};
    return @{AVVideoCodecKey: AVVideoCodecTypeH264,
             AVVideoWidthKey: @(videoSize.width),
             AVVideoHeightKey: @(videoSize.height),
             AVVideoCompressionPropertiesKey: compressionProperties};
}

- (NSDictionary *)audioOutputSettings {
#pragma mark å‚è€ƒäºï¼šhttps://blog.csdn.net/sinat_31177681/article/details/75252341
//    return @{AVEncoderBitRatePerChannelKey : @(28000),
//             AVFormatIDKey : @(kAudioFormatMPEG4AAC),
//             AVNumberOfChannelsKey : @(1),
//             AVSampleRateKey : @(22050)};
    
#pragma mark æºç çš„è®¾ç½®ï¼Œæœ‰å¾…è€ƒé‡
    AudioChannelLayout acl;
    bzero( &acl, sizeof(acl));
    acl.mChannelLayoutTag = kAudioChannelLayoutTag_Mono;
    
    return @{AVFormatIDKey: @(kAudioFormatMPEG4AAC),
             AVNumberOfChannelsKey: @1,
             AVSampleRateKey: @(44100.0),
             AVEncoderBitRateKey: @64000,
             AVChannelLayoutKey: [NSData dataWithBytes:&acl length: sizeof(acl)]};
}

- (void)viewDidLoad {
    [super viewDidLoad];
    [JPFileTool removeFile:JPMoviePath];
    self.writeLastView.alpha = 0.2;
    
#pragma mark GPUImageStillCamera
    self.camera = [[GPUImageStillCamera alloc] initWithSessionPreset:AVCaptureSessionPresetHigh cameraPosition:AVCaptureDevicePositionFront];
    self.camera.outputImageOrientation = UIInterfaceOrientationPortrait;
    self.camera.horizontallyMirrorFrontFacingCamera = YES;
    
#pragma mark ç¾é¢œæ»¤é•œ
    self.beautifyFilter = [[LFGPUImageBeautyFilter alloc] init];
    self.slider.value = self.beautifyFilter.beautyLevel;
    
#pragma mark æ»¤é•œç»„ï¼ˆæµ‹è¯•ï¼‰
//    GPUImageFilterGroup *filterGroup = [[GPUImageFilterGroup alloc] init];
//
//    GPUImageBrightnessFilter *brightnessFilter = [[GPUImageBrightnessFilter alloc] init];
//    GPUImageSketchFilter *sketchFilter = [[GPUImageSketchFilter alloc] init];
//    GPUImagePixellateFilter *pixellateFilter = [[GPUImagePixellateFilter alloc] init];
//
//
//    [filterGroup addFilter:sketchFilter];
//    [filterGroup addFilter:brightnessFilter];
//    [filterGroup addFilter:pixellateFilter];
//
//    [sketchFilter addTarget:brightnessFilter];
//    [brightnessFilter addTarget:pixellateFilter];
//
//    filterGroup.initialFilters = @[sketchFilter];
//    filterGroup.terminalFilter = pixellateFilter;
//
//    [self.camera addTarget:filterGroup];
//
//    self.filterGroup = filterGroup;
//    self.brightnessFilter = brightnessFilter;
//    self.sketchFilter = sketchFilter;
//    self.pixellateFilter = pixellateFilter;
    
#pragma mark åœºæ™¯æ»¤é•œ
    self.lookupFilter = [[GPUImageLookupFilter alloc] init];
    self.lookupFilter.intensity = 1;
    
#pragma mark ğŸŒ€æ»¤é•œ
    self.swirlFilter = [[GPUImageSwirlFilter alloc] init];
    self.swirlFilter.radius = 0;
    
#pragma mark å½•åˆ¶å™¨
    CGSize videoSize = CGSizeMake(720, 1280);
    JPMovieWriter *movieWriter = [[JPMovieWriter alloc] initWithMovieURL:[NSURL fileURLWithPath:JPMoviePath] size:videoSize fileType:AVFileTypeMPEG4 outputSettings:[self videoOutputSettings:videoSize]];
    movieWriter.delegate = self;
    movieWriter.encodingLiveVideo = YES; // æ˜¯å¦å¯¹è§†é¢‘è¿›è¡Œç¼–ç ï¼Œè¿™ä¸ªè®¾ç½®ä¸ºYESï¼ŒAVAssetWriterInputçš„expectsMediaDataInRealTimeåˆ™ä¹Ÿä¸ºYESï¼Œä»£è¡¨éœ€è¦ä»capture sessionå®æ—¶è·å–æ•°æ®
    movieWriter.assetWriter.movieFragmentInterval = kCMTimeInvalid; // MP4æ ¼å¼éœ€è¦è®¾ç½®è¿™ä¸ª
    movieWriter.shouldPassthroughAudio = NO;
    [movieWriter setHasAudioTrack:YES audioSettings:[self audioOutputSettings]];
    self.camera.audioEncodingTarget = (GPUImageMovieWriter *)movieWriter; //æŠŠé‡‡é›†çš„éŸ³é¢‘äº¤ç»™movieWriterå†™å…¥
    self.movieWriter = movieWriter;
    
#pragma mark æ°´å°æ»¤é•œ
    self.blendFilter = [[GPUImageAlphaBlendFilter alloc] init];
    self.blendFilter.mix = 1;
    
#pragma mark åˆ›å»ºé“¾
    // æ°´å°ä¸æ˜¾ç¤ºï¼Œåªå½•åˆ¶
//    [self.camera addTarget:self.beautifyFilter];
//    [self.beautifyFilter addTarget:self.lookupFilter];
//    [self.lookupFilter addTarget:self.swirlFilter];
//    [self.swirlFilter addTarget:self.previewView];
//    [self.swirlFilter addTarget:self.blendFilter];
//    [self.blendFilter addTarget:self.movieWriter];
    // æ°´å°èƒ½çœ‹åˆ°
    [self.camera addTarget:self.beautifyFilter];
    [self.beautifyFilter addTarget:self.lookupFilter];
    [self.lookupFilter addTarget:self.swirlFilter];
    [self.swirlFilter addTarget:self.blendFilter];
    [self.blendFilter addTarget:self.previewView];
    [self.blendFilter addTarget:self.movieWriter];
    
#pragma mark æ»¤é•œå›¾ç‰‡
    NSString *filterPath = [JPMainBundleResourcePath(@"FilterResource", @"bundle") stringByAppendingPathComponent:@"chaotuo.png"];
    UIImage *lookupTableImage = [UIImage imageWithContentsOfFile:filterPath];
    self.lookupImageSource = [[GPUImagePicture alloc] initWithImage:lookupTableImage];
    // å›¾åƒå¤„ç†
    [self.lookupImageSource addTarget:self.lookupFilter];
    [self.lookupImageSource useNextFrameForImageCapture];
    [self.lookupImageSource processImage];
    
#pragma mark æ°´å°
    UIView *watermarkView = [[UIView alloc] initWithFrame:CGRectMake(0, 0, JPPortraitScreenWidth, JPPortraitScreenWidth * (videoSize.height / videoSize.width))];
    watermarkView.backgroundColor = [UIColor clearColor];
    self.watermark = [[UIImageView alloc] initWithImage:[UIImage imageNamed:@"Lisa.png"]];
    self.watermark.contentMode = UIViewContentModeScaleAspectFit;
    self.watermark.frame = CGRectMake(0, 0, 220, 220);
    [watermarkView addSubview:self.watermark];
    self.watermark.center = CGPointMake(200, 200);
    
    self.element = [[JPWatermarkElement alloc] initWithView:watermarkView];
    [self.element addTarget:self.blendFilter];
    
    /*
     * å‚è€ƒï¼šhttps://github.com/BradLarson/GPUImage/issues/2211
     * ä¿®æ”¹GPUImageæºç ï¼Œä»¥ä¿®å¤<<å•æ¬¡åˆ·æ–°é™æ€æ°´å°å¯¼è‡´å´©æºƒ>>çš„é—®é¢˜ï¼š
        // TODO: This may not work
        outputFramebuffer = [[GPUImageContext sharedFramebufferCache] fetchFramebufferForSize:layerPixelSize textureOptions:self.outputTextureOptions onlyTexture:YES];
        [outputFramebuffer disableReferenceCounting]; // Add this line, because GPUImageTwoInputFilter.m frametime updatedMovieFrameOppositeStillImage is YES, but the secondbuffer not lock. æ·»åŠ æ­¤è¡Œï¼Œå› ä¸ºGPUImageTwoInputFilter.m frametime updatedMovieFrameOppositeStillImageä¸ºYESï¼Œä½†ç¬¬äºŒä¸ªç¼“å†²åŒºæœªé”å®šã€‚

        glBindTexture(GL_TEXTURE_2D, [outputFramebuffer texture]);
        // no need to use self.outputTextureOptions here, we always need these texture options
        glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, (int)layerPixelSize.width, (int)layerPixelSize.height, 0, GL_BGRA, GL_UNSIGNED_BYTE, imageData);
        
        free(imageData);
        
        for (id<GPUImageInput> currentTarget in targets)
        {
            if (currentTarget != self.targetToIgnoreForUpdates)
            {
                NSInteger indexOfObject = [targets indexOfObject:currentTarget];
                NSInteger textureIndexOfTarget = [[targetTextureIndices objectAtIndex:indexOfObject] integerValue];
                
                [currentTarget setInputSize:layerPixelSize atIndex:textureIndexOfTarget];
                [currentTarget setInputFramebuffer:outputFramebuffer atIndex:textureIndexOfTarget]; // add this line, because the outputFramebuffer is update above. æ·»åŠ æ­¤è¡Œï¼Œå› ä¸ºoutputFramebufferåœ¨ä¸Šé¢æ›´æ–°ã€‚
                [currentTarget newFrameReadyAtTime:frameTime atIndex:textureIndexOfTarget];
            }
        }
     */
    
    // ä¿®æ”¹æºç åå°±åªéœ€è¦updateä¸€ä¸‹å°±å¥½ï¼Œä¸å†éœ€è¦æ¯å¸§éƒ½update
    [self.element update];
    
    //æ¯ä¸€å¸§æ¸²æŸ“å®Œæ¯•åçš„å›è°ƒ
//    @jp_weakify(self);
//    [self.beautifyFilter setFrameProcessingCompletionBlock:^(GPUImageOutput *output, CMTime time) {
//        @jp_strongify(self);
//        if (!self) return;
//       //éœ€è¦è°ƒç”¨updateæ“ä½œï¼šå› ä¸ºupdateåªä¼šè¾“å‡ºä¸€æ¬¡çº¹ç†ä¿¡æ¯ï¼Œåªé€‚ç”¨äºä¸€å¸§ï¼Œæ‰€ä»¥éœ€è¦å®æ—¶æ›´æ–°æ°´å°å±‚å›¾åƒ
//       [self.element updateWithTimestamp:time];
//    }];
    
#pragma mark ğŸŒ€å®šæ—¶å™¨
    [self.userGrView addGestureRecognizer:[[UIPanGestureRecognizer alloc] initWithTarget:self action:@selector(panAction:)]];
    self.link = [CADisplayLink displayLinkWithTarget:JPTargetProxy(self) selector:@selector(linkHandle)];
    [self.link addToRunLoop:[NSRunLoop mainRunLoop] forMode:NSRunLoopCommonModes];
}

- (void)viewDidAppear:(BOOL)animated {
    [super viewDidAppear:animated];
    [UIApplication sharedApplication].idleTimerDisabled = YES;
    
    if (_isPreviewing) return;
    _isPreviewing = YES;
    // å¼€å§‹é‡‡é›†
    [self.camera startCameraCapture];
    // åœæ­¢é‡‡é›†
//    [self.camera stopCameraCapture];
}

- (void)viewDidDisappear:(BOOL)animated {
    [super viewDidDisappear:animated];
    [UIApplication sharedApplication].idleTimerDisabled = NO;
}

- (void)dealloc {
    [self.movieWriter cancelRecording];
    [self.camera removeAllTargets];
    [self.camera stopCameraCapture];
    
    [self.link invalidate];
    self.link = nil;
    
    JPLog(@"JPGPUImageCameraViewControlleræ­»äº†");
}

#pragma mark - æŒ‰é’®äº‹ä»¶

// åˆ‡æ¢æ‘„åƒå¤´
- (IBAction)switchCamera:(id)sender {
    [self.camera rotateCamera];
}

// å¼€å§‹å½•åˆ¶
- (IBAction)play:(id)sender {
    if (self.movieWriter.isRecording) {
        if (self.movieWriter.isPaused) {
            [JPProgressHUD showImage:nil status:@"ç»§ç»­" userInteractionEnabled:YES];
            self.movieWriter.paused = NO;
        } else {
            [JPProgressHUD showInfoWithStatus:@"å·²ç»åœ¨å½•åˆ¶" userInteractionEnabled:YES];
        }
        return;
    }
    
    // ç§»é™¤æ®‹å½±
    if (self.writeLastView.subviews.count > 0) {
        [UIView transitionWithView:self.writeLastView duration:0.15 options:UIViewAnimationOptionTransitionCrossDissolve animations:^{
            for (UIView *subview in self.writeLastView.subviews) {
                [subview removeFromSuperview];
            }
        } completion:nil];
    }
    
    [JPFileTool removeFile:JPMoviePath];
    
    [self.movieWriter startRecording];
    
    [JPProgressHUD showImage:nil status:@"å¼€å§‹å½•åˆ¶" userInteractionEnabled:YES];
}

// æš‚åœå½•åˆ¶
- (IBAction)pause:(id)sender {
    if (!self.movieWriter.isRecording) {
        return;
    }
    
    if (self.movieWriter.isPaused) {
        [JPProgressHUD showInfoWithStatus:@"å·²ç»æš‚åœ" userInteractionEnabled:YES];
    } else {
        [JPProgressHUD showImage:nil status:@"æš‚åœ" userInteractionEnabled:YES];
        self.movieWriter.paused = YES;
        
        // è®¾ç½®æ®‹å½±
        UIView *snView = [self.previewView snapshotViewAfterScreenUpdates:NO];
        snView.frame = self.writeLastView.bounds;
        [UIView transitionWithView:self.writeLastView duration:0.15 options:UIViewAnimationOptionTransitionCrossDissolve animations:^{
            for (UIView *subview in self.writeLastView.subviews) {
                [subview removeFromSuperview];
            }
            [self.writeLastView addSubview:snView];
        } completion:nil];
    }
}

// åœæ­¢å½•åˆ¶
- (IBAction)stop:(id)sender {
    if (!self.movieWriter.isRecording) {
        return;
    }
    
    // ç§»é™¤æ®‹å½±
    if (self.writeLastView.subviews.count > 0) {
        [UIView transitionWithView:self.writeLastView duration:0.15 options:UIViewAnimationOptionTransitionCrossDissolve animations:^{
            for (UIView *subview in self.writeLastView.subviews) {
                [subview removeFromSuperview];
            }
        } completion:nil];
    }
    
    [JPProgressHUD showWithStatus:@"æ­£åœ¨ç»“æŸå½•åˆ¶..."];
    [self.movieWriter finishRecordingWithCompletionHandler:^{
//        [self.movieWriter jp_removeAssetWriter]; // ä½¿ç”¨GPUImageMovieWriterå°±è°ƒç”¨è¿™æ–¹æ³•
        
        long long totalSize = [JPFileTool fileSize:JPMoviePath];
        NSString *sizeStr = JPFileSizeString(totalSize);
        
        dispatch_async(dispatch_get_main_queue(), ^{
            [JPProgressHUD dismiss];
            UIAlertAction *action1 = [UIAlertAction actionWithTitle:@"ä¿å­˜ç›¸å†Œ" style:UIAlertActionStyleDefault handler:^(UIAlertAction * _Nonnull action) {
                [JPProgressHUD showWithStatus:@"æ­£åœ¨ä¿å­˜å½•åƒ..."];
                [JPPhotoToolSI saveVideoToAppAlbumWithFileURL:[NSURL fileURLWithPath:JPMoviePath] successHandle:^(NSString *assetID) {
                    [JPProgressHUD showSuccessWithStatus:@"ä¿å­˜æˆåŠŸ" userInteractionEnabled:YES];
                } failHandle:^(NSString *assetID, BOOL isGetAlbumFail, BOOL isSaveFail) {
                    [JPProgressHUD showErrorWithStatus:@"ä¿å­˜å¤±è´¥" userInteractionEnabled:YES];
                }];
            }];
            UIAlertAction *action2 = [UIAlertAction actionWithTitle:@"è§‚çœ‹å½•åƒ" style:UIAlertActionStyleDefault handler:^(UIAlertAction * _Nonnull action) {
//                UIViewController *vc = [[NSClassFromString(@"JPPlayerViewController") alloc] init];
//                [self.navigationController pushViewController:vc animated:YES];
                [AVPlayerViewController playLocalVideo:JPMoviePath isAutoPlay:YES];
            }];
            UIAlertAction *action3 = [UIAlertAction actionWithTitle:@"åˆ é™¤" style:UIAlertActionStyleDestructive handler:^(UIAlertAction * _Nonnull action) {
                [JPProgressHUD showWithStatus:@"æ­£åœ¨åˆ é™¤å½•åƒ..."];
                dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
                    [JPFileTool removeFile:JPMoviePath];
                    dispatch_async(dispatch_get_main_queue(), ^{
                        [JPProgressHUD showSuccessWithStatus:@"åˆ é™¤æˆåŠŸ" userInteractionEnabled:YES];
                    });
                });
            }];
            UIAlertAction *cancel = [UIAlertAction actionWithTitle:@"å¥½çš„" style:UIAlertActionStyleCancel handler:nil];
            [UIAlertController jp_alertControllerWithStyle:UIAlertControllerStyleAlert title:@"å½•åˆ¶å®Œæˆ" message:sizeStr actions:@[action1, action2, action3, cancel] fromVC:self];
        });
    }];
}

// é‡‡é›†ä¸€å¸§ç”»é¢
- (IBAction)capturePhoto:(id)sender {
    [self.camera capturePhotoAsImageProcessedUpToFilter:self.brightnessFilter withCompletionHandler:^(UIImage *processedImage, NSError *error) {
        JPLog(@"%@", processedImage);
        self.placeholderView.image = processedImage;
    }];
}

- (IBAction)sliderDidChanged:(UISlider *)sender {
    float value = sender.value;
    
//    self.lookupFilter.intensity = value;
    self.beautifyFilter.beautyLevel = value;
    self.beautifyFilter.brightLevel = value;
    
    if (self.camera && self.camera.inputCamera) {
        AVCaptureDevice *device = (AVCaptureDevice *)self.camera.inputCamera;
        if ([device lockForConfiguration:nil]) {
            device.videoZoomFactor = 1 + value;
            [device unlockForConfiguration];
        }
    }
}

static BOOL aaa = NO;
- (IBAction)changeFilter:(id)sender {
    if (!self.lookupFilter) {
        return;
    }
    
    aaa = !aaa;
    
    UIImage *lookupTableImage;
    if (aaa) {
        NSString *filterPath = [JPMainBundleResourcePath(@"FilterResource", @"bundle") stringByAppendingPathComponent:@"landiao.png"];
        lookupTableImage = [UIImage imageWithContentsOfFile:filterPath];
    } else {
        NSString *filterPath = [JPMainBundleResourcePath(@"FilterResource", @"bundle") stringByAppendingPathComponent:@"chaotuo.png"];
        lookupTableImage = [UIImage imageWithContentsOfFile:filterPath];
    }
    
    [self.lookupImageSource removeOutputFramebuffer];
    [self.lookupImageSource removeAllTargets];
    
    self.lookupImageSource = [[GPUImagePicture alloc] initWithImage:lookupTableImage];
    [self.lookupImageSource addTarget:self.lookupFilter];
    [self.lookupImageSource useNextFrameForImageCapture];
    [self.lookupImageSource processImage];
}

- (IBAction)shuiyin:(UIButton *)sender {
    self.watermark.center = CGPointMake(JPRandomNumber(0, JPPortraitScreenWidth), JPRandomNumber(JPNavTopMargin, JPPortraitScreenHeight - JPDiffTabBarH));
    
    // ä¿®æ”¹æºç åå°±åªéœ€è¦updateä¸€ä¸‹å°±å¥½ï¼Œä¸å†éœ€è¦æ¯å¸§éƒ½update
    [self.element update];
}

#pragma mark - <JPMovieWriterDelegate>
//#pragma mark - <GPUImageMovieWriterDelegate>

- (void)movieRecordingCompleted {
    JPLog(@"movieRecordingCompleted");
}

- (void)movieRecordingFailedWithError:(NSError*)error {
    JPLog(@"movieRecordingFailedWithError");
}

#pragma mark - panæ‰‹åŠ¿

- (void)panAction:(UIPanGestureRecognizer *)panGR {
    if (panGR.state == UIGestureRecognizerStateBegan || panGR.state == UIGestureRecognizerStateChanged) {
        self.isPaning = YES;
        CGPoint location = [panGR locationInView:self.userGrView];
        self.swirlFilter.center = CGPointMake(location.x / self.userGrView.jp_width, location.y / self.userGrView.jp_height);
    } else {
        self.isPaning = NO;
    }
}

- (void)linkHandle {
    CGFloat radius = self.swirlFilter.radius;
    if (self.isPaning) {
        radius += 0.01;
    } else {
        radius -= 0.01;
    }
    if (radius > 1) {
        radius = 1;
    } else if (radius < 0) {
        radius = 0;
    }
    self.swirlFilter.radius = radius;
}

@end
